{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORmuvMyoEMndfjVt2R5EWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meganrice/BSAN-6070-Computer-Assignments/blob/main/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niHXo1_8tjsk"
      },
      "source": [
        "**This is an eMail Spam Classifier that uses Naive Bayes supervised machine learning algorithm.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUg5s327tatu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc85ae78-7e4e-4d55-eead-c8204f167f34"
      },
      "source": [
        "#importing packages\n",
        "import os #miscellaneous operating system interfaces\n",
        "import numpy as np #numerical python\n",
        "from collections import Counter #container datatypes, dictionary subclass for counting hashable objects\n",
        "from sklearn.naive_bayes import GaussianNB #Gaussian Naive Bayes, classification\n",
        "from sklearn.metrics import accuracy_score #accuracy classification score\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ7G83B-uWFQ"
      },
      "source": [
        "**This function builds a Dictionary of most common 3000 words from all the email content. First it adds all words and symbols in the dictionary. Then it removes all non-alpha-numeric characters and any single character alpha-numeric characters. After this is complete it shrinks the Dictionary by keeping only most common 3000 words in the dictionary. It returns the Dictionary.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VzzungjNNQv"
      },
      "source": [
        "def make_dict(root_directory):\n",
        "    all_words_list = []\n",
        "    emails_list = [os.path.join(root_directory,fsp) for fsp in os.listdir(root_directory)]\n",
        "    for email in emails_list:\n",
        "        with open(email) as e:\n",
        "            for sentence in e:\n",
        "                all_words = sentence.split()\n",
        "                all_words_list += all_words\n",
        "    word_dict = Counter(all_words_list)\n",
        "    remove_list = list(word_dict)\n",
        "    \n",
        "    for w in remove_list:\n",
        "        if w.isalpha() == False:\n",
        "            del word_dict[w]\n",
        "        elif len(w) == 1:\n",
        "            del word_dict[w]\n",
        "    word_dict = word_dict.most_common(3000)\n",
        "    return word_dict"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlah2dMRgW1_"
      },
      "source": [
        "**Code Explanation**\n",
        "\n",
        "**Line 1:** Defining a function named most_common_dict which contains the parameter/argument root_directory\n",
        "\n",
        "**Line 2:** Creating an empty list for total words which we can use later, called all_words_list\n",
        "\n",
        "**Line 3:** Creating a list, emails_list, using os.path.join() method to join path components root_directory and fsp (a path-like object representing a file system path)\n",
        "\n",
        "Using a for loop, for fsp in the a list containing the names of the entries in the driectory given by path using method os.listdir() with root_directory as the path argument (the directory which needs to be explored)\n",
        "\n",
        "**Line 4:** Using a for loop, for email in emails_list, meaning execute the set of statements below once for each item (email) in the list (emails_list)\n",
        "\n",
        "**Line 5:** Using the open() function to open file email and save it as e\n",
        "\n",
        "**Line 6:** Using another for loop, for sentence in e, meaning execute the set of statements below once for each item (sentence) in the list (e)\n",
        "\n",
        "**Line 7:** Creating a list of all words using split() method which splits a string into a list where each word is a list item\n",
        "\n",
        "**Line 8:** Creating another list of all words but this time using addition assignment which adds a value and the variable and assigns the result to that variable\n",
        "\n",
        "**Line 9:** Creating a dictionary, word_dict, using Counter method from collections, a counter is a container that stores elements as dictionary keys, and their counts are stored as dictionary values\n",
        "\n",
        "**Line 10:** Creating a list, to_remove_list, from word_dict\n",
        "\n",
        "**Line 11:** Using a for loop, for w in list_to_remove, meaning execute the set of statments below once for each item (w) in the list (remove_list)\n",
        "\n",
        "**Line 12/13:** If w includes not all alphabet letter characters (using isalpha() method), then delete it from word_dict\n",
        "\n",
        "**Line 14/15:** If w character length is equal to 1 (using isalpha() method), then delete it from word_dict\n",
        "\n",
        "**Line 16:** Taking the top 3000 most common item in word_dict and saving it back into word_dict\n",
        "\n",
        "**Line 17:** Returning the dictionary word_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXj9Yp4fwRvA"
      },
      "source": [
        "**This function extracts feature columns and populates their values (Feature Matrix of 3000 comumns and rows equal to the number of email files). The function also analyzes the File Names of each email file and decides if it's a Spam or not based on the naming convention. Based on this the function also creates the Labelled Data Column. This function is used to extract the training dataset as well as the testing dataset and returns the Feature Dataset and the Label column.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BWLi-MqwVf8"
      },
      "source": [
        "def ext_features(mail_directory):\n",
        "  files_list = [os.path.join(mail_directory,fp) for fp in os.listdir(mail_directory)]\n",
        "  feat_matrix = np.zeros((len(files_list),3000))\n",
        "  train_labs = np.zeros(len(files_list))\n",
        "  c = 1;\n",
        "  dID = 0;\n",
        "  for f in files_list:\n",
        "    with open(f) as fil:\n",
        "      for x, line in enumerate(fil):\n",
        "        if x ==2:\n",
        "          sentence = line.split()\n",
        "          for w in sentence: \n",
        "            wID = 0\n",
        "            for x, y in enumerate(word_dict):\n",
        "              if y[0] == w:\n",
        "                wID = x\n",
        "                feat_matrix[dID,wID] = sentence.count(w)\n",
        "      train_labs[dID] = 0;\n",
        "      fpath_Tokens = f.split('/')\n",
        "      last_Token = fpath_Tokens[len(fpath_Tokens)-1]\n",
        "      if last_Token.startswith(\"spmsg\"):\n",
        "        train_labs[dID] = 1;\n",
        "        c = c + 1\n",
        "      dID = dID + 1\n",
        "  return feat_matrix, train_labs     "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJPdJlwrN8uJ"
      },
      "source": [
        "**Code Explanation**\n",
        "\n",
        "**Line 1:** Defining a function named ext_features which contains the parameter/argument mail_directory\n",
        "\n",
        "**Line 2:** Creating a list, files_list, using os.path.join() method to join path components mail_directory and fp (a path-like object representing a file system path)\n",
        "\n",
        "Using a for loop, for fp in the a list containing the names of the entries in the driectory given by path using method os.listdir() with mail_directory as the path argument (the directory which needs to be explored)\n",
        "\n",
        "**Line 3:** Using Numpy's zeros() function to return a new array of given shape and type, with zeros\n",
        "\n",
        "The shape being given is the length of the files_list for the rows and 3000 for the columns\n",
        "\n",
        "The matrix this creates is being saved into feat_matrix\n",
        "\n",
        "**Line 4:** Using Numpy's zeros() function to return a new array of given shap and type, with zeros\n",
        "\n",
        "The shape of this matrix is the length of the files_list and it is being saved into train_labs\n",
        "\n",
        "**Line 5:** Saving 1 into c\n",
        "\n",
        "**Line 6:** Saving 0 into dID\n",
        "\n",
        "**Line 7:** Using a for loop, for f in files_list, using the open() function to open f and save it as fil\n",
        "\n",
        "**Line 8:** Using for loop, for x, line use emumerate() method on fil to add a counter to an iterable and return it in a form of an enumerate object\n",
        "\n",
        "**Line 9/10:** If statement, if x is 2, then use split() method on the line\n",
        "\n",
        "**Line 11:** Using a for loop, for w in sentence, wID = 0\n",
        "\n",
        "**Line 12:** Using for loop, for x, y use emumerate() method on word_dict to add a counter to an iterable and return it in a form of an enumerate object\n",
        "\n",
        "**Line 13:** If statement, if y[0] is w, then wID equals x and feat_matrix[dID, wID] equals setence count of w\n",
        "\n",
        "**Line 14:** Set train_labs[dID] equal to 0\n",
        "\n",
        "**Line 15:** Using split() method on fil with argument / and saving it to fpath_Tokens\n",
        "\n",
        "**Line 16:** Taking the length of fpath_Tokens - 1, and saving it into last_Token\n",
        "\n",
        "**Line 17/18/19/20:** If statement, if last_Token using startswith() method, argument \"spmsg\", then train_labs[dID] equals 1, then c equals c + 1, then dID equals dID + 1\n",
        "\n",
        "**Line 21:** Returning feat_matrix and train_labs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92ByW24jwacv"
      },
      "source": [
        "**The section is the main Program that calls the above two functions and gets executed first. First it \"trains\" the model using model.fit function and Training Dataset. After that it scores the Test Data set by running the Trained Model with the Test Data set. At the end it prints the model performance in terms of accuracy score.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNeTBCIgwdMs"
      },
      "source": [
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/test-mails'"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CqypEuGw8Jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e31a7e-f4fa-434d-e364-c0aa20118464"
      },
      "source": [
        "word_dict = make_dict(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "feat_matrix, labs = ext_features(TRAIN_DIR)\n",
        "test_feat_matrix, test_labs = ext_features(TEST_DIR)\n",
        "\n",
        "model = GaussianNB() #Used in classification and it assumes that features follow a normal distribution\n",
        "\n",
        "print (\"Training Model using Gaussian Naive Bayes algorithm .....\")\n",
        "model.fit(feat_matrix, labs) #training the model\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labs = model.predict(test_feat_matrix) #testing the model\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labs, predicted_labs)) #accuracy score is percentage of correct predictions"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naive Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcN6wu2uxSYB"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ]
}